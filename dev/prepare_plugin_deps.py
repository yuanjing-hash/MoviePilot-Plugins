"""
æ’ä»¶å†…åµŒä¾èµ–å‡†å¤‡è„šæœ¬

åŠŸèƒ½:
- æ”¯æŒå¯é€‰çš„é¡¶å±‚ç™½åå• (`top_level_packages`) è¿›è¡Œæ€§èƒ½ä¼˜åŒ–ã€‚
- æ”¯æŒåŸºäºä½œè€… (`author_match`) å’ŒåŒ…å (`package_name_match`) çš„æ ¸å¿ƒåŒ¹é…è§„åˆ™ã€‚
- æ”¯æŒé»‘åå• (`exclude_packages`) è¿›è¡Œç»†ç²’åº¦æ’é™¤ã€‚
- é‡‡ç”¨â€œä¿¡ä»»è¾¹ç•Œâ€å‰ªæç­–ç•¥ï¼Œé«˜æ•ˆåœ°è¿›è¡Œä¾èµ–åˆ†æã€‚
- åœ¨éå†æ—¶æ•è·å¹¶éµå®ˆå­ä¾èµ–çš„ç‰ˆæœ¬é™åˆ¶ï¼Œç¡®ä¿å…¼å®¹æ€§ã€‚
- è‡ªåŠ¨ä¸‹è½½æ‰€æœ‰ç›®æ ‡å¹³å°çš„ .whl æ–‡ä»¶ã€‚
- ä¸ä¿®æ”¹åŸå§‹çš„ `requirements.txt` æ–‡ä»¶ã€‚
"""

import json
import re
import shutil
import subprocess
import sys
from pathlib import Path
from typing import Dict, List, Optional, Set

import requests


try:
    PLUGIN_ID = "p115strmhelper"
    PLUGIN_SOURCE_DIR = (
        Path("/Users/rem/Documents/Git/MoviePilot-Plugins/plugins.v2") / PLUGIN_ID
    )
except KeyError:
    raise ValueError("é”™è¯¯: ç¯å¢ƒå˜é‡ PLUGIN_FULL_PATH æœªè®¾ç½®ã€‚")


PLUGIN_REQUIREMENTS_FILE = PLUGIN_SOURCE_DIR / "requirements.txt"
RESOLVED_REQUIREMENTS_FILE = PLUGIN_SOURCE_DIR / "requirements.lock.txt"
CONFIG_FILE = PLUGIN_SOURCE_DIR / "bundle.json"
TARGET_PLATFORMS = {
    "win_amd64",
    "win32",
    "macosx_11_0_arm64",
    "macosx_10_9_x86_64",
    "manylinux2014_x86_64",
    "manylinux2014_aarch64",
    "manylinux_2_24_armv7l",
}
TARGET_PYTHON_VERSION = "312"
TARGET_ABI = f"cp{TARGET_PYTHON_VERSION}"


# ç”¨äºç¼“å­˜å·²æŸ¥è¯¢è¿‡çš„åŒ…ä¿¡æ¯ï¼Œé¿å…é‡å¤ç½‘ç»œè¯·æ±‚
package_info_cache: Dict[str, Optional[str]] = {}


def log(*args, **kwargs):
    """
    å°†æ¶ˆæ¯æ‰“å°åˆ°æ ‡å‡†é”™è¯¯æµ (stderr)ï¼Œé¿å…æ±¡æŸ“æ ‡å‡†è¾“å‡ºã€‚
    """
    print(*args, file=sys.stderr, **kwargs)


def get_package_author(package_name: str) -> Optional[str]:
    """
    é€šè¿‡ PyPI çš„ JSON API æŸ¥è¯¢å¹¶ç¼“å­˜æŒ‡å®šåŒ…çš„ä½œè€…ä¿¡æ¯ã€‚

    Args:
        package_name (str): éœ€è¦æŸ¥è¯¢çš„åŒ…åã€‚

    Returns:
        Optional[str]: åŒ…çš„ä½œè€…ä¿¡æ¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæŸ¥è¯¢å¤±è´¥æˆ–ä¸å­˜åœ¨åˆ™è¿”å› Noneã€‚
    """
    normalized_name = package_name.lower()
    # æ£€æŸ¥ç¼“å­˜ä¸­æ˜¯å¦å·²æœ‰è¯¥åŒ…çš„ä¿¡æ¯
    if normalized_name in package_info_cache:
        return package_info_cache[normalized_name]

    log(f"   L æ­£åœ¨æŸ¥è¯¢ PyPI API: '{package_name}'...")
    try:
        # å‘èµ·ç½‘ç»œè¯·æ±‚
        response = requests.get(
            f"https://pypi.org/pypi/{package_name}/json", timeout=15
        )
        response.raise_for_status()  # å¦‚æœè¯·æ±‚å¤±è´¥ (å¦‚ 404)ï¼Œåˆ™æŠ›å‡ºå¼‚å¸¸
        # è§£æ JSON æ•°æ®å¹¶æå–ä½œè€…ä¿¡æ¯
        author = response.json().get("info", {}).get("author")
        package_info_cache[normalized_name] = author
        return author
    except requests.RequestException as e:
        # å¤„ç†ç½‘ç»œè¯·æ±‚æˆ–è§£æè¿‡ç¨‹ä¸­çš„å¼‚å¸¸
        log(f"    [è­¦å‘Š] æ— æ³•è·å– '{package_name}' çš„ä¿¡æ¯: {e}")
        package_info_cache[normalized_name] = None
        return None


def generate_lock_file() -> bool:
    """
    ä½¿ç”¨ pip-compile è§£æä¾èµ–ï¼Œå¹¶ç”Ÿæˆä¸€ä¸ªè·¨å¹³å°çš„ã€åŒ…å«å“ˆå¸Œå€¼çš„é”æ–‡ä»¶ã€‚

    Returns:
        bool: å¦‚æœé”æ–‡ä»¶æˆåŠŸç”Ÿæˆåˆ™è¿”å› Trueï¼Œå¦åˆ™è¿”å› Falseã€‚
    """
    log("[Info] æ­£åœ¨ç”Ÿæˆä¾èµ–é”æ–‡ä»¶")
    try:
        # è°ƒç”¨ pip-compile å‘½ä»¤
        subprocess.run(
            [
                # æ³¨æ„: åœ¨ä¸åŒç¯å¢ƒä¸­ï¼Œæ­¤è·¯å¾„å¯èƒ½éœ€è¦è°ƒæ•´
                "pip-compile",
                str(PLUGIN_REQUIREMENTS_FILE),
                "--output-file",
                str(RESOLVED_REQUIREMENTS_FILE),
                "--resolver=backtracking",  # ä½¿ç”¨å›æº¯ç®—æ³•è§£å†³å¤æ‚çš„ä¾èµ–å†²çª
                "--generate-hashes",  # ä¸ºæ¯ä¸ªåŒ…ç”Ÿæˆå“ˆå¸Œå€¼ï¼Œç¡®ä¿å®‰å…¨æ€§
                "--quiet",  # ç²¾ç®€è¾“å‡º
            ],
            check=True,
            capture_output=True,
            text=True,
            encoding="utf-8",
        )
        log(f"  -> æˆåŠŸç”Ÿæˆé€šç”¨çš„ä¾èµ–é”æ–‡ä»¶: {RESOLVED_REQUIREMENTS_FILE.name}")
        return True
    except (subprocess.CalledProcessError, FileNotFoundError) as e:
        # æ•è·å‘½ä»¤æ‰§è¡Œå¤±è´¥æˆ–æ‰¾ä¸åˆ°å‘½ä»¤çš„å¼‚å¸¸
        log(
            "[Error] pip-compile æ‰§è¡Œå¤±è´¥ã€‚è¯·ç¡®ä¿ pip-tools å·²å®‰è£…ä¸” Python ç¯å¢ƒé…ç½®æ­£ç¡®ã€‚"
        )
        if hasattr(e, "stderr"):
            log(f"[Error]é”™è¯¯è¯¦æƒ…: {e.stderr}")
        return False


def parse_resolved_requirements(file_path: Path) -> Dict[str, str]:
    """
    è§£æç”± pip-compile ç”Ÿæˆçš„ã€å®Œå…¨å›ºå®šçš„ requirements.lock.txt æ–‡ä»¶ã€‚

    Args:
        file_path (Path): é”æ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        Dict[str, str]: ä¸€ä¸ªå­—å…¸ï¼Œé”®æ˜¯å°å†™çš„åŒ…åï¼Œå€¼æ˜¯å®Œæ•´çš„åŒ…ç‰ˆæœ¬å£°æ˜ (å¦‚ 'requests==2.28.1')ã€‚
    """
    specs = {}
    with open(file_path, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            # å¿½ç•¥æ³¨é‡Šã€å“ˆå¸Œå€¼ã€ç¼–è¾‘æ¨¡å¼ç­‰æ— å…³è¡Œ
            if line and not line.startswith(("#", "-e", "-r", "--hash")):
                # é€šè¿‡ ' \' åˆ†å‰²ï¼Œå»é™¤è¡Œå°¾çš„å“ˆå¸Œä¿¡æ¯
                spec_line = line.split(" \\")[0].strip()
                # æ­£åˆ™åŒ¹é… "åŒ…å==ç‰ˆæœ¬å·" æ ¼å¼
                match = re.match(r"([a-zA-Z0-9_.-]+)==([0-9a-zA-Z_.-]+)", spec_line)
                if match:
                    package_name = match.group(1).lower()
                    specs[package_name] = spec_line
    return specs


def load_bundling_config(config_file: Path) -> Dict:
    """
    åŠ è½½å¹¶è§£æ bundle.json é…ç½®æ–‡ä»¶ã€‚

    Args:
        config_file (Path): bundle.json æ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        Dict: åŒ…å«æ‰€æœ‰æ†ç»‘è§„åˆ™çš„é…ç½®å­—å…¸ã€‚
    """
    with open(config_file, "r", encoding="utf-8") as f:
        config = json.load(f)

    # æå–å¹¶å¤„ç†å„é¡¹é…ç½®
    return {
        "top_level_whitelist": {
            pkg.lower() for pkg in config.get("top_level_packages", [])
        },
        "author_match_list": {
            rule["value"]
            for rule in config.get("rules", [])
            if rule.get("strategy") == "author_match"
        },
        "package_match_list": {
            pkg.lower()
            for rule in config.get("rules", [])
            if rule.get("strategy") == "package_name_match"
            for pkg in rule.get("value", [])
        },
        "exclude_list": {pkg.lower() for pkg in config.get("exclude_packages", [])},
    }


def get_top_level_packages(requirements_file: Path) -> Set[str]:
    """
    ä»åŸå§‹çš„ requirements.txt æ–‡ä»¶ä¸­è§£æå‡ºé¡¶å±‚ä¾èµ–åŒ…çš„åç§°ã€‚

    Args:
        requirements_file (Path): åŸå§‹ä¾èµ–æ–‡ä»¶çš„è·¯å¾„ã€‚

    Returns:
        Set[str]: ä¸€ä¸ªåŒ…å«æ‰€æœ‰é¡¶å±‚ä¾èµ–åŒ…åï¼ˆå°å†™ï¼‰çš„é›†åˆã€‚
    """
    top_level_packages = set()
    with open(requirements_file, "r", encoding="utf-8") as f:
        for line in f:
            line = line.strip()
            # å¿½ç•¥æ³¨é‡Šç­‰éåŒ…å£°æ˜è¡Œ
            if line and not line.startswith(("#", "-e", "-r", "--")):
                # æ­£åˆ™æå–åŒ…åéƒ¨åˆ†
                match = re.match(r"([a-zA-Z0-9_.-]+)", line)
                if match:
                    top_level_packages.add(match.group(1).lower())
    return top_level_packages


def filter_packages_to_bundle(
    resolved_specs: Dict[str, str], config: Dict, top_level_packages: Set[str]
) -> Set[str]:
    """
    æ ¹æ®åŠ è½½çš„è§„åˆ™ï¼Œä»æ‰€æœ‰è§£æå‡ºçš„ä¾èµ–ä¸­ç­›é€‰å‡ºéœ€è¦è¢«æ†ç»‘çš„åŒ…ã€‚

    Args:
        resolved_specs (Dict[str, str]): æ‰€æœ‰å·²è§£æçš„ä¾èµ–åŒ…åŠå…¶ç‰ˆæœ¬å£°æ˜ã€‚
        config (Dict): ä» bundle.json åŠ è½½çš„é…ç½®è§„åˆ™ã€‚
        top_level_packages (Set[str]): é¡¶å±‚ä¾èµ–åŒ…åé›†åˆã€‚

    Returns:
        Set[str]: éœ€è¦è¢«æ†ç»‘çš„åŒ…åï¼ˆå°å†™ï¼‰é›†åˆã€‚
    """
    packages_to_bundle = set()
    log("\n[Info] æ­£åœ¨æ ¹æ®è§„åˆ™ç­›é€‰éœ€è¦æ†ç»‘çš„åŒ…...")

    for package, spec in resolved_specs.items():
        # è§„åˆ™ 1: åº”ç”¨é¡¶å±‚ç™½åå•è¿‡æ»¤
        is_top_level = package in top_level_packages
        if (
            config["top_level_whitelist"]
            and is_top_level
            and package not in config["top_level_whitelist"]
        ):
            log(f"â“˜ [é¡¶å±‚è¿‡æ»¤] '{package}' ä¸åœ¨ top_level_packages ç™½åå•ä¸­ï¼Œè·³è¿‡ã€‚")
            continue
        if is_top_level:
            log(f"â“˜ [é¡¶å±‚è¿‡æ»¤] '{package}' é€šè¿‡é¡¶å±‚è¿‡æ»¤ï¼Œå¼€å§‹æ£€æŸ¥å†…éƒ¨å­ä¾èµ–...")

        # è§„åˆ™ 2: åº”ç”¨é»‘åå•æ’é™¤
        if package in config["exclude_list"]:
            log(f"ğŸš« [æ’é™¤åˆ—è¡¨] '{package}' åœ¨ exclude_packages ä¸­ï¼Œè·³è¿‡ã€‚")
            continue

        # è§„åˆ™ 3: åº”ç”¨æ ¸å¿ƒåŒ¹é…è§„åˆ™ï¼ˆä½œè€…æˆ–åŒ…åï¼‰
        author = get_package_author(package)
        if (author and author in config["author_match_list"]) or (
            package in config["package_match_list"]
        ):
            log(f"âœ”ï¸  [åŒ¹é…æˆåŠŸ] '{package}' (ä½œè€…: {author})ã€‚å°†è¢«æ†ç»‘ã€‚")
            packages_to_bundle.add(package)

    return packages_to_bundle


def download_wheels(package_specs: List[str], wheels_dir: Path):
    """
    ä¸ºç»™å®šçš„åŒ…ç‰ˆæœ¬å£°æ˜åˆ—è¡¨ï¼Œä¸‹è½½æ‰€æœ‰ç›®æ ‡å¹³å°çš„ .whl æ–‡ä»¶ã€‚
    é‡‡ç”¨ä¸¤é˜¶æ®µç­–ç•¥ï¼šå…ˆä¸‹è½½é€šç”¨å’Œå½“å‰å¹³å°åŒ…ï¼Œå†ä¸ºå…¶ä»–å¹³å°è¡¥å……ä¸‹è½½ã€‚

    Args:
        package_specs (List[str]): éœ€è¦ä¸‹è½½çš„åŒ…çš„ç²¾ç¡®ç‰ˆæœ¬å£°æ˜åˆ—è¡¨ (e.g., ['requests==2.28.1'])ã€‚
        wheels_dir (Path): ç”¨äºå­˜æ”¾ä¸‹è½½çš„ .whl æ–‡ä»¶çš„ç›®å½•ã€‚
    """
    log("\n[Info] å¼€å§‹ä¸‹è½½ Wheels æ–‡ä»¶...")
    sorted_specs = sorted(package_specs)

    # é˜¶æ®µ 1: ä¸‹è½½é€šç”¨åŒ… (py3-none-any) å’Œå½“å‰ç¯å¢ƒçš„åŒ…
    log("[Info] -> æ­£åœ¨ä¸‹è½½é€šç”¨åŒ…å’Œå½“å‰ç¯å¢ƒçš„åŒ…...")
    try:
        subprocess.run(
            [
                "pip3",
                "download",
                "--only-binary=:all:",  # åªä¸‹è½½ wheel æ–‡ä»¶
                "--python-version",
                TARGET_PYTHON_VERSION,  # æŒ‡å®šç›®æ ‡ Python ç‰ˆæœ¬
                "--abi",
                TARGET_ABI,  # æŒ‡å®šç›®æ ‡ Python ABI
                "--no-deps",  # ä¸ä¸‹è½½å­ä¾èµ–
                "-d",
                str(wheels_dir),  # æŒ‡å®šä¸‹è½½ç›®å½•
            ]
            + sorted_specs,
            check=True,
            capture_output=True,
            text=True,
            encoding="utf-8",
        )
    except subprocess.CalledProcessError as e:
        log(f"[Error] ä¸‹è½½æ—¶å‡ºé”™: {e.stderr}")

    # é˜¶æ®µ 2: éå†æ‰€æœ‰ç›®æ ‡å¹³å°ï¼Œè¡¥å……ä¸‹è½½ç‰¹å®šå¹³å°çš„äºŒè¿›åˆ¶åŒ…
    for platform_target in TARGET_PLATFORMS:
        log(f"[Info] -> æ­£åœ¨ä¸ºå¹³å°è¡¥å……: {platform_target}...")
        subprocess.run(
            [
                "pip3",
                "download",
                "--only-binary=:all:",  # åªä¸‹è½½ wheel æ–‡ä»¶
                "--platform",
                platform_target,  # æŒ‡å®šç›®æ ‡å¹³å°
                "--python-version",
                TARGET_PYTHON_VERSION,  # æŒ‡å®šç›®æ ‡ Python ç‰ˆæœ¬
                "--abi",
                TARGET_ABI,  # æŒ‡å®šç›®æ ‡ Python ABI
                "--no-deps",  # ä¸ä¸‹è½½å­ä¾èµ–
                "-d",
                str(wheels_dir),  # æŒ‡å®šä¸‹è½½ç›®å½•
            ]
            + sorted_specs,
            # check=False å› ä¸ºæŸäº›åŒ…å¯èƒ½æ²¡æœ‰ç‰¹å®šå¹³å°çš„ wheelï¼Œè¿™ä¸åº”è§†ä¸ºè‡´å‘½é”™è¯¯
            check=False,
            capture_output=True,
            text=True,
            encoding="utf-8",
        )


def cleanup(files_to_remove: List[Path]):
    """
    æ¸…ç†è„šæœ¬è¿è¡Œè¿‡ç¨‹ä¸­äº§ç”Ÿçš„ä¸´æ—¶æ–‡ä»¶ã€‚

    Args:
        files_to_remove (List[Path]): éœ€è¦è¢«åˆ é™¤çš„æ–‡ä»¶è·¯å¾„åˆ—è¡¨ã€‚
    """
    log("\n[Info] æ­£åœ¨æ¸…ç†ä¸´æ—¶æ–‡ä»¶...")
    for file_path in files_to_remove:
        if file_path.exists():
            file_path.unlink()
            log(f"[Info] -> å·²åˆ é™¤: {file_path.name}")


def main():
    """
    ä¸»æ‰§è¡Œå‡½æ•°ï¼Œåè°ƒæ•´ä¸ªä¾èµ–å‡†å¤‡æµç¨‹ã€‚
    """
    log(f"[Info] å¼€å§‹ä¸ºæ’ä»¶ '{PLUGIN_SOURCE_DIR.name}' å‡†å¤‡å†…åµŒä¾èµ–")

    # æ£€æŸ¥å¿…è¦æ–‡ä»¶æ˜¯å¦å­˜åœ¨ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™æå‰é€€å‡º
    if not PLUGIN_REQUIREMENTS_FILE.exists():
        log(
            f"[Info] æœªæ‰¾åˆ°æ’ä»¶çš„ä¾èµ–æ–‡ä»¶ '{PLUGIN_REQUIREMENTS_FILE.name}'ï¼Œæ— éœ€å¤„ç†ã€‚"
        )
        return
    if not CONFIG_FILE.exists():
        log(f"[Info] æœªæ‰¾åˆ°æ†ç»‘è§„åˆ™æ–‡ä»¶ '{CONFIG_FILE.name}'ï¼Œæ— éœ€å¤„ç†ã€‚")
        return

    # ç”Ÿæˆä¾èµ–é”æ–‡ä»¶
    if not generate_lock_file():
        return  # å¦‚æœç”Ÿæˆå¤±è´¥ï¼Œåˆ™ç»ˆæ­¢è„šæœ¬

    # è§£æé”æ–‡ä»¶å’Œé…ç½®æ–‡ä»¶
    resolved_specs = parse_resolved_requirements(RESOLVED_REQUIREMENTS_FILE)
    config = load_bundling_config(CONFIG_FILE)
    top_level_packages = get_top_level_packages(PLUGIN_REQUIREMENTS_FILE)

    # æ ¹æ®è§„åˆ™ç­›é€‰éœ€è¦æ†ç»‘çš„åŒ…
    packages_to_bundle = filter_packages_to_bundle(
        resolved_specs, config, top_level_packages
    )

    # å¦‚æœæ²¡æœ‰éœ€è¦æ†ç»‘çš„åŒ…ï¼Œåˆ™æ¸…ç†å¹¶é€€å‡º
    if not packages_to_bundle:
        log("\n[Info] åˆ†æåï¼Œæœªå‘ç°æ²¡æœ‰éœ€è¦æ†ç»‘çš„åŒ…ã€‚")
        cleanup([RESOLVED_REQUIREMENTS_FILE])
        return False

    log(f"\n[info] åˆ†æå®Œæˆï¼å…±æ‰¾åˆ° {len(packages_to_bundle)} ä¸ªéœ€è¦æ†ç»‘çš„åŒ…:")
    # ä½¿ç”¨ sorted ç¡®ä¿æ¯æ¬¡è¾“å‡ºé¡ºåºä¸€è‡´
    log(sorted(list(packages_to_bundle)))

    # å‡†å¤‡ä¸‹è½½ç›®å½•å¹¶æ‰§è¡Œä¸‹è½½
    wheels_dir_in_plugin = PLUGIN_SOURCE_DIR / "wheels"
    if wheels_dir_in_plugin.exists():
        shutil.rmtree(wheels_dir_in_plugin)  # æ¸…ç†æ—§çš„ wheels ç›®å½•
    wheels_dir_in_plugin.mkdir(parents=True)

    # ä»ç­›é€‰ç»“æœä¸­æå–ç²¾ç¡®çš„ç‰ˆæœ¬å£°æ˜
    specs_to_download = [resolved_specs[pkg] for pkg in packages_to_bundle]
    log(f"\n[Info] å°†è¦ä¸‹è½½ä»¥ä¸‹åŒ…çš„ç²¾ç¡®ç‰ˆæœ¬: {specs_to_download}")
    download_wheels(specs_to_download, wheels_dir_in_plugin)

    # æ¸…ç†ä¸´æ—¶çš„é”æ–‡ä»¶
    cleanup([RESOLVED_REQUIREMENTS_FILE])

    log(f"[Info] '{PLUGIN_SOURCE_DIR}' ç›®å½•ç°åœ¨å·²åŒ…å« 'wheels' ç›®å½•ã€‚")
    log("[Info] å†…åµŒä¾èµ–å‡†å¤‡æˆåŠŸ!")
    return True


if __name__ == "__main__":
    main()
